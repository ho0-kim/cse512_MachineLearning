{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW2\n",
    "==\n",
    "#### Multinomial Classification and Suppport Vector Machine\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "folder_name = 'datasethw2'\n",
    "file_name = ['data1.txt', 'data2.txt', 'data3.txt']\n",
    "training_data_rate = 0.8\n",
    "\n",
    "load_data = []\n",
    "\n",
    "for i in range(3):\n",
    "    load_data.append(pd.read_csv(os.path.join(folder_name, file_name[i]), sep='\\t', header = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amount_train = int(training_data_rate*load_data[0].shape[0])\n",
    "    \n",
    "def data_suffle_each_class(d):\n",
    "    for i in range(3):\n",
    "        d[i] = shuffle(d[i])\n",
    "    return d\n",
    "\n",
    "''' Functions for Question 1'''\n",
    "\n",
    "def train_test_data(data):\n",
    "    train = []\n",
    "    test = []\n",
    "    for i in range(3):\n",
    "        train.append(data[i][:amount_train])\n",
    "        test.append(data[i][amount_train:])\n",
    "        \n",
    "    train_set = np.concatenate((train[0], train[1]), axis=0)\n",
    "    train_set = np.concatenate((train_set, train[2]), axis=0)\n",
    "    np.random.shuffle(train_set)\n",
    "    \n",
    "    test_set = np.concatenate((test[0], test[1]), axis=0)\n",
    "    test_set = np.concatenate((test_set, test[2]), axis=0)\n",
    "    \n",
    "    return train_set, test_set, test_set[:20, :], test_set[20:40, :], test_set[40:,:]\n",
    "\n",
    "def x_data1(dataset):\n",
    "    return dataset[:,:5]\n",
    "\n",
    "''' Functions for Question 2'''\n",
    "\n",
    "def dataset_excluding(nth_feature, data):\n",
    "    train_set, test_set, _, _, _ = train_test_data(data)\n",
    "    \n",
    "    train_set = np.delete(train_set, nth_feature, axis=1)\n",
    "    test_set = np.delete(test_set, nth_feature, axis=1)\n",
    "    \n",
    "    return train_set, test_set, test_set[:20, :], test_set[20:40, :], test_set[40:,:]\n",
    "\n",
    "def x_data2(dataset):\n",
    "    return dataset[:,:4]\n",
    "\n",
    "\n",
    "\n",
    "def x_data(dataset, q_num):\n",
    "    return x_data2(dataset) if q_num == 2 else x_data1(dataset)\n",
    "\n",
    "def y_data(dataset):\n",
    "    return dataset[:,-1].reshape([dataset.shape[0], 1]) - 1 # for one-hot encoding, subtract 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 3\n",
    "learning_rate = 0.01\n",
    "training_epochs = 20 #\n",
    "steps = 2000\n",
    "\n",
    "# define model\n",
    "\n",
    "class Multinomial_Logistic_Classifier:\n",
    "\n",
    "    def __init__(self, sess, name, question_num):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self.question_num = question_num\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # input place holders\n",
    "            if self.question_num == 1:\n",
    "                self.X = tf.placeholder(tf.float32, [None, 5])\n",
    "                self.W = tf.Variable(tf.random_normal([5, nb_classes]), name='weight')\n",
    "            elif self.question_num == 2:\n",
    "                self.X = tf.placeholder(tf.float32, [None, 4])\n",
    "                self.W = tf.Variable(tf.random_normal([4, nb_classes]), name='weight')\n",
    "            \n",
    "            self.Y = tf.placeholder(tf.int32, [None, 1])\n",
    "            \n",
    "            self.Y_one_hot = tf.one_hot(self.Y, nb_classes) # one-hot\n",
    "            self.Y_one_hot = tf.reshape(self.Y_one_hot, [-1, nb_classes])\n",
    "            \n",
    "            self.b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "            \n",
    "        logits = tf.matmul(self.X, self.W) + self.b\n",
    "        self.hypothesis = tf.nn.softmax(logits)\n",
    "            \n",
    "        cost_i = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=self.Y_one_hot)\n",
    "        \n",
    "        self.cost = tf.reduce_mean(cost_i)\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
    "        \n",
    "        self.prediction = tf.argmax(self.hypothesis, 1)\n",
    "        self.correct_prediction = tf.equal(self.prediction, tf.argmax(self.Y_one_hot, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return self.sess.run(self.correct_prediction, feed_dict={self.X: x_test})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test})\n",
    "\n",
    "    def train(self, x_data, y_data):\n",
    "        return self.sess.run([self.cost, self.optimizer, self.W, self.b], feed_dict={self.X: x_data, self.Y: y_data})\n",
    "    \n",
    "    def values_Wb(self):\n",
    "        W_val, b_val = self.sess.run([self.W, self.b])\n",
    "        return W_val, b_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training(q_num, nth_feature=None):\n",
    "    avg_accuracy = 0\n",
    "    avg_acc_class1 = 0\n",
    "    avg_acc_class2 = 0\n",
    "    avg_acc_class3 = 0\n",
    "    max_accuracy = 0\n",
    "    \n",
    "    for i in range(10):\n",
    "        # dataset\n",
    "        if q_num == 1:\n",
    "            train_set, test_set, test_set_1, test_set_2, test_set_3 = train_test_data(data_suffle_each_class(load_data))\n",
    "        elif q_num == 2:\n",
    "            train_set, test_set, test_set_1, test_set_2, test_set_3 = dataset_excluding(nth_feature, data_suffle_each_class(load_data))\n",
    "    \n",
    "        # initialize\n",
    "        sess = tf.Session()\n",
    "        m1 = Multinomial_Logistic_Classifier(sess, \"m1\", q_num)\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        #print('Learning Started!')\n",
    "\n",
    "        # train my model\n",
    "        for epoch in range(training_epochs):\n",
    "            avg_cost = 0\n",
    "        \n",
    "            for j in range(steps):\n",
    "                c, _, W_val, b_val = m1.train(x_data(train_set, q_num), y_data(train_set))\n",
    "                avg_cost += c / steps\n",
    "    \n",
    "            #print('Epoch:', '%02d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "        #print('Learning Finished!')\n",
    "        \n",
    "        acc = m1.get_accuracy(x_data(test_set, q_num), y_data(test_set))\n",
    "        acc_class1 = m1.get_accuracy(x_data(test_set_1, q_num), y_data(test_set_1))\n",
    "        acc_class2 = m1.get_accuracy(x_data(test_set_2, q_num), y_data(test_set_2))\n",
    "        acc_class3 = m1.get_accuracy(x_data(test_set_3, q_num), y_data(test_set_3))\n",
    "    \n",
    "        avg_accuracy += acc / 10\n",
    "        avg_acc_class1 += acc_class1 / 10\n",
    "        avg_acc_class2 += acc_class2 / 10\n",
    "        avg_acc_class3 += acc_class3 / 10\n",
    "            \n",
    "        if max_accuracy < acc :\n",
    "            max_accuracy = acc\n",
    "            max_W = W_val\n",
    "            max_b = b_val\n",
    "\n",
    "    return avg_accuracy, max_accuracy, avg_acc_class1, avg_acc_class2, avg_acc_class3, max_W, max_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Multinomial Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy: 0.800000000\n",
      "average accuracy for class 1: 0.864999992\n",
      "average accuracy for class 2: 0.830000001\n",
      "\n",
      "average accuracy for class 3: 0.705000001\n",
      "nthe highest accuracy: 0.883333325\n",
      "weight:\n",
      " [[ 1.0360097   1.3999194   0.89743996]\n",
      " [-0.13516912  0.17269608  0.10517832]\n",
      " [-1.2849635   1.0764158  -0.78427213]\n",
      " [-1.1136543   1.6155427   0.7139656 ]\n",
      " [ 0.5250165   1.1507765   1.2004191 ]]\n",
      "bias:\n",
      " [ 5.2689934 -6.844008   1.342023 ]\n"
     ]
    }
   ],
   "source": [
    "avg_accuracy, max_accuracy, avg_acc_class1, avg_acc_class2, avg_acc_class3, W, b = training(1)\n",
    "\n",
    "print('average accuracy:', '{:.9f}'.format(avg_accuracy))\n",
    "print('average accuracy for class 1:', '{:.9f}'.format(avg_acc_class1))\n",
    "print('average accuracy for class 2:', '{:.9f}'.format(avg_acc_class2))\n",
    "print('average accuracy for class 3:', '{:.9f}'.format(avg_acc_class3))\n",
    "print('\\nthe highest accuracy:', '{:.9f}'.format(max_accuracy))\n",
    "print('weight:\\n', W)\n",
    "print('bias:\\n', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Multinomial Classification & Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   < A model excluding the feature at column 0 >\n",
      "average accuracy: 0.755000013\n",
      "average accuracy for class 1: 0.850000006\n",
      "average accuracy for class 2: 0.764999998\n",
      "average accuracy for class 3: 0.650000000\n",
      "the highest accuracy: 0.800000012\n",
      "weight:\n",
      " [[-0.71209604 -0.15263793 -0.45918292]\n",
      " [-1.3664936   0.2814427  -0.4648291 ]\n",
      " [-0.4416324   1.2639712   1.0551808 ]\n",
      " [-1.3364556  -0.30226645 -0.83470106]]\n",
      "bias:\n",
      " [ 4.171041   -4.3506637  -0.25914234]\n",
      "\n",
      "   < A model excluding the feature at column 1 >\n",
      "average accuracy: 0.828333330\n",
      "average accuracy for class 1: 0.869999993\n",
      "average accuracy for class 2: 0.834999996\n",
      "average accuracy for class 3: 0.780000007\n",
      "the highest accuracy: 0.883333325\n",
      "weight:\n",
      " [[-0.10264365  0.42055514 -0.14231323]\n",
      " [-0.5148925   2.3349345   0.50254554]\n",
      " [-1.1095403   0.5762804   0.14800042]\n",
      " [ 0.8398855   1.3390179   1.2579081 ]]\n",
      "bias:\n",
      " [ 5.493771  -5.4288354  2.6585095]\n",
      "\n",
      "   < A model excluding the feature at column 2 >\n",
      "average accuracy: 0.734999996\n",
      "average accuracy for class 1: 0.865000010\n",
      "average accuracy for class 2: 0.684999996\n",
      "average accuracy for class 3: 0.655000007\n",
      "the highest accuracy: 0.783333361\n",
      "weight:\n",
      " [[-0.12909222  0.14141017 -0.27851254]\n",
      " [-0.501746   -0.06998561 -0.27936128]\n",
      " [-0.9034062   0.47092497  0.34635237]\n",
      " [-1.0350657   0.06747928 -0.43283552]]\n",
      "bias:\n",
      " [ 4.330229  -5.913997   1.5248063]\n",
      "\n",
      "   < A model excluding the feature at column 3 >\n",
      "average accuracy: 0.741666669\n",
      "average accuracy for class 1: 0.854999995\n",
      "average accuracy for class 2: 0.805000007\n",
      "average accuracy for class 3: 0.565000004\n",
      "the highest accuracy: 0.816666663\n",
      "weight:\n",
      " [[ 0.40602112  0.79171324  0.30961126]\n",
      " [-0.7945556  -0.53408027 -0.5980883 ]\n",
      " [-0.82560885  1.1866767  -0.27512613]\n",
      " [-1.7005206  -0.00691396 -0.39334705]]\n",
      "bias:\n",
      " [ 4.8407373 -6.1396646  1.4997874]\n",
      "\n",
      "   < A model excluding the feature at column 4 >\n",
      "average accuracy: 0.814999992\n",
      "average accuracy for class 1: 0.894999999\n",
      "average accuracy for class 2: 0.825000000\n",
      "average accuracy for class 3: 0.725000006\n",
      "the highest accuracy: 0.866666675\n",
      "weight:\n",
      " [[-0.8201985  -0.28106672 -0.8375888 ]\n",
      " [ 0.03375107  0.13611214  0.12962776]\n",
      " [-1.1861694   1.5676681  -0.09783702]\n",
      " [-1.3683645   1.0503572   0.42012948]]\n",
      "bias:\n",
      " [ 4.1869187 -6.751715   1.3469859]\n"
     ]
    }
   ],
   "source": [
    "for k in range(5):\n",
    "    print(\"\\n   < A model excluding the feature at column\", k, \">\")\n",
    "    \n",
    "    avg_accuracy, max_accuracy, avg_acc_class1, avg_acc_class2, avg_acc_class3, W, b = training(2, k)\n",
    "    \n",
    "    print('average accuracy:', '{:.9f}'.format(avg_accuracy))\n",
    "    print('average accuracy for class 1:', '{:.9f}'.format(avg_acc_class1))\n",
    "    print('average accuracy for class 2:', '{:.9f}'.format(avg_acc_class2))\n",
    "    print('average accuracy for class 3:', '{:.9f}'.format(avg_acc_class3))\n",
    "    print('the highest accuracy:', '{:.9f}'.format(max_accuracy))\n",
    "    print('weight:\\n', W)\n",
    "    print('bias:\\n', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the result, the accuracy of the models excluding feature 1 and feature 4 is higher then Q1's result.  \n",
    "The accuracy of the model except feature 4 has improved by 1.8405% compared to Q1.  \n",
    "The accuracy of the model except feature 1 has improved by 3.4205% compared to Q1.  \n",
    "\n",
    "More features would improve the performance of Machine Learning (ML). However, noisy data has adverse influences on the ML models. Therefore, we should carefully refine data to make the model work well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average test accuracy:  0.8016666666666666 \n",
      "accuracy for class 1: 0.9099999999999999 \n",
      "accuracy for class 2: 0.7749999999999999 \n",
      "accuracy for class 3: 0.7200000000000001\n"
     ]
    }
   ],
   "source": [
    "avg_acc = avg_acc_1 = avg_acc_2 = avg_acc_3 = 0\n",
    "\n",
    "for i in range(10):\n",
    "    # get shuffled data\n",
    "    train_set, test_set, test_set_1, test_set_2, test_set_3 = train_test_data(data_suffle_each_class(load_data))\n",
    "\n",
    "    # fit the SVM model\n",
    "    svm_model = svm.SVC(decision_function_shape='ovr')\n",
    "    svm_model.fit(x_data(train_set, 3), y_data(train_set).ravel())\n",
    "    \n",
    "    # mean accuracy\n",
    "    accu = svm_model.score(x_data(test_set, 3), y_data(test_set).ravel())\n",
    "    accu_class1 = svm_model.score(x_data(test_set_1, 3), y_data(test_set_1).ravel())\n",
    "    accu_class2 = svm_model.score(x_data(test_set_2, 3), y_data(test_set_2).ravel())\n",
    "    accu_class3 = svm_model.score(x_data(test_set_3, 3), y_data(test_set_3).ravel())\n",
    "    \n",
    "    avg_acc += accu / 10.0\n",
    "    avg_acc_1 += accu_class1 / 10.0\n",
    "    avg_acc_2 += accu_class2 / 10.0\n",
    "    avg_acc_3 += accu_class3 / 10.0\n",
    "    \n",
    "print('average test accuracy: ', avg_acc, \\\n",
    "      '\\naccuracy for class 1:', avg_acc_1, \\\n",
    "      '\\naccuracy for class 2:', avg_acc_2, \\\n",
    "      '\\naccuracy for class 3:', avg_acc_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
